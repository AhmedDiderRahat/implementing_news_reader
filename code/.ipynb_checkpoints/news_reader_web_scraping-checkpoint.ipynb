{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import requests\n",
    "import os.path as path\n",
    "\n",
    "from functools import reduce\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not exist\n"
     ]
    }
   ],
   "source": [
    "if path.exists('../input_data/news_paper_data.csv'):\n",
    "    df = pd.read_csv('../input_data/news_paper_data.csv')\n",
    "    print('exsit')\n",
    "else:\n",
    "    print('not exist')\n",
    "    columns = ['node_id','title','url','category']\n",
    "    df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [node_id, title, url, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3075086</td>\n",
       "      <td>Ensure safe handling of hazardous chemicals: CPD</td>\n",
       "      <td>/business/news/ensure-safe-handling-hazardous-...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3074891</td>\n",
       "      <td>Dhaka stocks keep falling</td>\n",
       "      <td>/business/economy/stock/news/dhaka-stocks-keep...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3074571</td>\n",
       "      <td>MTB wins Asiamoney Best Bank Award</td>\n",
       "      <td>/business/organisation-news/news/mtb-wins-asia...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3074941</td>\n",
       "      <td>Bangladesh Bank raises interest rate on EDF lo...</td>\n",
       "      <td>/business/news/bangladesh-bank-raises-interest...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3075021</td>\n",
       "      <td>Dhaka stocks extend losses</td>\n",
       "      <td>/business/economy/stock/news/dhaka-stocks-exte...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id                                              title  \\\n",
       "0  3075086   Ensure safe handling of hazardous chemicals: CPD   \n",
       "1  3074891                          Dhaka stocks keep falling   \n",
       "2  3074571                 MTB wins Asiamoney Best Bank Award   \n",
       "3  3074941  Bangladesh Bank raises interest rate on EDF lo...   \n",
       "4  3075021                         Dhaka stocks extend losses   \n",
       "\n",
       "                                                 url  category  \n",
       "0  /business/news/ensure-safe-handling-hazardous-...  business  \n",
       "1  /business/economy/stock/news/dhaka-stocks-keep...  business  \n",
       "2  /business/organisation-news/news/mtb-wins-asia...  business  \n",
       "3  /business/news/bangladesh-bank-raises-interest...  business  \n",
       "4  /business/economy/stock/news/dhaka-stocks-exte...  business  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base url of the news paper\n",
    "base_url = 'https://www.thedailystar.net'\n",
    "\n",
    "# all important categories\n",
    "categories = ['business', 'sports', 'entertainment']\n",
    "\n",
    "# counts new entry using this run\n",
    "new_count = 0\n",
    "\n",
    "for category in categories:\n",
    "    \n",
    "    #print(base_url+category)\n",
    "    page = requests.get(base_url+'/'+category)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # to analyze the newspaper I got all the headline of intended categories are under h2 or h3 tag\n",
    "    temp_h2 = soup.find_all('h2')\n",
    "    temp_h3 = soup.find_all('h3')\n",
    "\n",
    "    all_url = temp_h2 + temp_h3\n",
    "\n",
    "    for data in all_url:\n",
    "        temp_d = data.find('a')\n",
    "\n",
    "        url = str(temp_d.get('href'))\n",
    "        title = temp_d.get_text()\n",
    "\n",
    "        # check its on the category or not\n",
    "        url_arr = url.split('/')\n",
    "\n",
    "        url_arr = [d for d in url_arr if len(d.strip())>0]\n",
    "\n",
    "        if category in url_arr[0]:\n",
    "\n",
    "            # check url has a node id or not\n",
    "            last_part = str(url_arr[len(url_arr)-1])\n",
    "\n",
    "            if '-' in last_part:\n",
    "                lp_arr = last_part.split('-')\n",
    "                node_id = str(lp_arr[len(lp_arr)-1])\n",
    "\n",
    "                if node_id.isnumeric():\n",
    "                    if url not in df.node_id:\n",
    "                        new_count += 1\n",
    "                        df = df.append({'node_id': node_id, 'title': title, 'url': url, 'category': category}, \n",
    "                                       ignore_index=True)\n",
    "\n",
    "            # is else part we can get the sub-categories\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of data points are: 90\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of data points are: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_parser(soup, node_id):\n",
    "    \n",
    "    article_context = soup.find(id=\"node-\"+node_id)\n",
    "\n",
    "    article = ''\n",
    "    only_date = ''\n",
    "\n",
    "    try:\n",
    "        dt_context = article_context.find(\"div\", {\"class\": \"date text-10\"}).get_text()\n",
    "        dt_input_arr = str(dt_context).split('Last update on:')\n",
    "        dt_input = str(dt_input_arr[1]).strip().replace(',', '')\n",
    "\n",
    "        dt_arr = dt_input.split(' ')\n",
    "        only_date = dt_arr[1] + '-' + dt_arr[2] + '-' + dt_arr[3]\n",
    "\n",
    "        only_date = datetime.strptime(only_date, '%b-%d-%Y').strftime('%d-%m-%Y')\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(f'Error: {str(ex)}')\n",
    "\n",
    "    for paragraph in article_context.find_all('p'):\n",
    "        text = paragraph.get_text()\n",
    "        \n",
    "        if len(text) > 0:\n",
    "            article = article + ' ' + text\n",
    "    \n",
    "    return only_date, article.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_list = []\n",
    "article_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    node_id = row['node_id']\n",
    "    \n",
    "    new_page = requests.get(base_url+row['url'])\n",
    "    \n",
    "    current_soup = BeautifulSoup(new_page.content, 'html.parser')\n",
    "    \n",
    "    results = article_parser(current_soup, node_id)\n",
    "    \n",
    "    date_list.append(results[0])\n",
    "    article_list.append(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(df.columns.get_loc(\"title\")+1, \"date\", date_list)\n",
    "df.insert(df.columns.get_loc(\"category\")+1, \"article\", article_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../input_data/news_paper_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
